{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01799fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/fake-news-pair-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee0aeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tid1  tid2                          title1_zh                  title2_zh   \n",
       "id                                                                             \n",
       "0      0     1      2017养老保险又新增两项，农村老人人人可申领，你领到了吗   警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京  \\\n",
       "3      2     3  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小   \n",
       "1      2     4  \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港       GDP首超香港？深圳澄清：还差一点点……   \n",
       "\n",
       "                                            title1_en   \n",
       "id                                                      \n",
       "0   There are two new old-age insurance benefits f...  \\\n",
       "3   \"If you do not come to Shenzhen, sooner or lat...   \n",
       "1   \"If you do not come to Shenzhen, sooner or lat...   \n",
       "\n",
       "                                            title2_en      label  \n",
       "id                                                                \n",
       "0   Police disprove \"bird's nest congress each per...  unrelated  \n",
       "3   Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated  \n",
       "1   The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀CSV\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"train/train.csv\", index_col=0)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214be9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4d386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title1_zh                  title2_zh      label\n",
       "id                                                                         \n",
       "0       2017养老保险又新增两项，农村老人人人可申领，你领到了吗   警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京  unrelated\n",
       "3   \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小  unrelated\n",
       "1   \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港       GDP首超香港？深圳澄清：还差一点点……  unrelated"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['title1_zh', \n",
    "        'title2_zh', \n",
    "        'label']\n",
    "train = train.loc[:, cols]\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e27057c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 320552\n"
     ]
    }
   ],
   "source": [
    "num_rows = train.shape[0]\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75eb1f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Meng', 'Lee,', 'a', 'data', 'scientist', 'based', 'in', 'Tokyo.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I am Meng Lee, a data scientist based in Tokyo.'\n",
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "14e8652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\AU\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.691 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[pair('我', 'r'),\n",
       " pair('是', 'v'),\n",
       " pair('李孟', 'nr'),\n",
       " pair('，', 'x'),\n",
       " pair('在', 'p'),\n",
       " pair('東京', 'ns'),\n",
       " pair('工作', 'vn'),\n",
       " pair('的', 'uj'),\n",
       " pair('數據', 'n'),\n",
       " pair('科學家', 'n')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "text = '我是李孟，在東京工作的數據科學家'\n",
    "words = pseg.cut(text)\n",
    "[word for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34f0ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_tokenizer(text):\n",
    "    words = pseg.cut(text)\n",
    "    return ' '.join([\n",
    "        word for word, flag in words if flag != 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title1_tokenized'] = \\\n",
    "    train.loc[:, 'title1_zh'] \\\n",
    "         .apply(jieba_tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f04a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title2_tokenized'] = \\\n",
    "    train.loc[:, 'title2_zh'] \\\n",
    "         .fillna('') \\\n",
    "         .apply(jieba_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "378b8744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>label</th>\n",
       "      <th>title1_tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</td>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</td>\n",
       "      <td>去年深圳GDP首超香港？深圳统计局辟谣：还差611亿</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油</td>\n",
       "      <td>吃了30年食用油才知道，一片大蒜轻松鉴别地沟油</td>\n",
       "      <td>agreed</td>\n",
       "      <td>用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title1_zh                   title2_zh      label   \n",
       "id                                                                             \n",
       "0       2017养老保险又新增两项，农村老人人人可申领，你领到了吗    警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京  unrelated  \\\n",
       "3   \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小  unrelated   \n",
       "1   \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港        GDP首超香港？深圳澄清：还差一点点……  unrelated   \n",
       "2   \"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  去年深圳GDP首超香港？深圳统计局辟谣：还差611亿  unrelated   \n",
       "9                \"用大蒜鉴别地沟油的方法,怎么鉴别地沟油     吃了30年食用油才知道，一片大蒜轻松鉴别地沟油     agreed   \n",
       "\n",
       "                                   title1_tokenized  \n",
       "id                                                   \n",
       "0          2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗  \n",
       "3   你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港  \n",
       "1   你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港  \n",
       "2   你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港  \n",
       "9                        用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, 0:4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "752b44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecode = 'utf-8-sig'\n",
    "train.to_csv(\"fake-news_jieba_10000.csv\", encoding = ecode, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6c094de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"fake-news_jieba_10000.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d291499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d093eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title2_tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title1_zh</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</th>\n",
       "      <td>警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京</td>\n",
       "      <td>警方 辟谣 鸟巢 大会 每人 领 5 万 仍 有 老人 坚持 进京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</th>\n",
       "      <td>深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小</td>\n",
       "      <td>深圳 GDP 首 超 香港 深圳 统计局 辟谣 只是 差距 在 缩小</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</th>\n",
       "      <td>GDP首超香港？深圳澄清：还差一点点……</td>\n",
       "      <td>GDP 首 超 香港 深圳 澄清 还 差 一点点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</th>\n",
       "      <td>去年深圳GDP首超香港？深圳统计局辟谣：还差611亿</td>\n",
       "      <td>去年 深圳 GDP 首 超 香港 深圳 统计局 辟谣 还 差 611 亿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油</th>\n",
       "      <td>吃了30年食用油才知道，一片大蒜轻松鉴别地沟油</td>\n",
       "      <td>吃 了 30 年 食用油 才 知道 一片 大蒜 轻松 鉴别 地沟油</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title2_zh   \n",
       "title1_zh                                                       \n",
       " 2017养老保险又新增两项，农村老人人人可申领，你领到了吗       警方辟谣“鸟巢大会每人领5万” 仍有老人坚持进京  \\\n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港   深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小   \n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港        GDP首超香港？深圳澄清：还差一点点……   \n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  去年深圳GDP首超香港？深圳统计局辟谣：还差611亿   \n",
       "\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油                  吃了30年食用油才知道，一片大蒜轻松鉴别地沟油   \n",
       "\n",
       "                                                       title2_tokenized  \n",
       "title1_zh                                                                \n",
       " 2017养老保险又新增两项，农村老人人人可申领，你领到了吗        警方 辟谣 鸟巢 大会 每人 领 5 万 仍 有 老人 坚持 进京  \n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港    深圳 GDP 首 超 香港 深圳 统计局 辟谣 只是 差距 在 缩小  \n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港              GDP 首 超 香港 深圳 澄清 还 差 一点点  \n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  去年 深圳 GDP 首 超 香港 深圳 统计局 辟谣 还 差 611 亿  \n",
       "\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油                  吃 了 30 年 食用油 才 知道 一片 大蒜 轻松 鉴别 地沟油  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, [0, 3]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c995b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 320552\n"
     ]
    }
   ],
   "source": [
    "num_rows = train.shape[0]\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c86a8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "MAX_NUM_WORDS = 10000\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e24731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641104,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_x1 = train.title1_tokenized\n",
    "corpus_x2 = train.title2_tokenized\n",
    "corpus = pd.concat([\n",
    "    corpus_x1, corpus_x2])\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76a03ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_x1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61c71323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title1_zh</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017养老保险又新增两项，农村老人人人可申领，你领到了吗</th>\n",
       "      <td>2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</th>\n",
       "      <td>你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</th>\n",
       "      <td>你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港</th>\n",
       "      <td>你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油</th>\n",
       "      <td>用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             title\n",
       "title1_zh                                                                         \n",
       " 2017养老保险又新增两项，农村老人人人可申领，你领到了吗            2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗\n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港\n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港\n",
       "\"你不来深圳，早晚你儿子也要来\"，不出10年深圳人均GDP将超香港  你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港\n",
       "\"用大蒜鉴别地沟油的方法,怎么鉴别地沟油                                    用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(corpus.iloc[:5],\n",
    "             columns=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b1b88c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#title1_tokenized 可能存在數字 使用map 把內容轉成字串\n",
    "corpus_x1 = train.title1_tokenized.map(str)\n",
    "corpus_x2 = train.title2_tokenized.map(str)\n",
    "corpus = pd.concat([corpus_x1, corpus_x2])\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7aa02265",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = tokenizer \\\n",
    "    .texts_to_sequences(corpus_x1)\n",
    "x2_train = tokenizer \\\n",
    "    .texts_to_sequences(corpus_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7645bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[217, 1268, 32, 1178, 5967, 25, 489, 2877, 116, 5559, 4, 1850, 2, 13],\n",
       " [4,\n",
       "  10,\n",
       "  47,\n",
       "  678,\n",
       "  2558,\n",
       "  4,\n",
       "  166,\n",
       "  34,\n",
       "  17,\n",
       "  47,\n",
       "  5150,\n",
       "  63,\n",
       "  15,\n",
       "  678,\n",
       "  4502,\n",
       "  3211,\n",
       "  23,\n",
       "  284,\n",
       "  1181],\n",
       " [4,\n",
       "  10,\n",
       "  47,\n",
       "  678,\n",
       "  2558,\n",
       "  4,\n",
       "  166,\n",
       "  34,\n",
       "  17,\n",
       "  47,\n",
       "  5150,\n",
       "  63,\n",
       "  15,\n",
       "  678,\n",
       "  4502,\n",
       "  3211,\n",
       "  23,\n",
       "  284,\n",
       "  1181],\n",
       " [4,\n",
       "  10,\n",
       "  47,\n",
       "  678,\n",
       "  2558,\n",
       "  4,\n",
       "  166,\n",
       "  34,\n",
       "  17,\n",
       "  47,\n",
       "  5150,\n",
       "  63,\n",
       "  15,\n",
       "  678,\n",
       "  4502,\n",
       "  3211,\n",
       "  23,\n",
       "  284,\n",
       "  1181],\n",
       " [31, 320, 3372, 3062, 1, 95, 98, 3372, 3062]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03cc44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 20\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "x1_train = pad_sequences(x1_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x2_train = pad_sequences(x2_train, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc93af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ed9a4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,  217, 1268,   32, 1178, 5967,\n",
       "         25,  489, 2877,  116, 5559,    4, 1850,    2,   13])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9da435b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecode = 'utf-8-sig'\n",
    "x1_train_df=pd.DataFrame(x1_train)\n",
    "x2_train_df=pd.DataFrame(x2_train)\n",
    "x1_train_df = x1_train_df.iloc[:100]\n",
    "x2_train_df = x2_train_df.iloc[:100]\n",
    "x1_train_df.to_csv(\"fake-news_tokenized_sequences_x1_train.csv\", encoding = ecode, index=False)\n",
    "x2_train_df.to_csv(\"fake-news_tokenized_sequences_x2_train.csv\", encoding = ecode, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0ee73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# 定義每一個分類對應到的索引數字\n",
    "label_to_index = {\n",
    "    'unrelated': 0, \n",
    "    'agreed': 1, \n",
    "    'disagreed': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "385d58b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將分類標籤對應到剛定義的數字\n",
    "y_train = train.label.apply(\n",
    "    lambda x: label_to_index[x])\n",
    "\n",
    "y_train = np.asarray(y_train) \\\n",
    "            .astype('float32')\n",
    "y_train = keras \\\n",
    "    .utils \\\n",
    "    .to_categorical(y_train)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63b92a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'每 1 維度則對應到 1 個分類：\\n\\n[1, 0, 0] 代表 label 為 unrelated\\n[0, 1, 0] 代表 label 為 agreed\\n[0, 0, 1] 代表 label 為 disagreed'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''每 1 維度則對應到 1 個分類：\n",
    "\n",
    "[1, 0, 0] 代表 label 為 unrelated\n",
    "[0, 1, 0] 代表 label 為 agreed\n",
    "[0, 0, 1] 代表 label 為 disagreed'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b6edd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320552, 20)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x1_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2f85d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320552, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2dc07652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection \\\n",
    "    import train_test_split\n",
    "\n",
    "VALIDATION_RATIO = 0.1\n",
    "# 小彩蛋\n",
    "RANDOM_STATE = 9527\n",
    "\n",
    "x1_train, x1_val, \\\n",
    "x2_train, x2_val, \\\n",
    "y_train, y_val = \\\n",
    "    train_test_split(\n",
    "        x1_train, x2_train, y_train, \n",
    "        test_size=VALIDATION_RATIO, \n",
    "        random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c46a379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "----------\n",
      "x1_train: (288496, 20)\n",
      "x2_train: (288496, 20)\n",
      "y_train : (288496, 3)\n",
      "----------\n",
      "x1_val:   (32056, 20)\n",
      "x2_val:   (32056, 20)\n",
      "y_val :   (32056, 3)\n",
      "----------\n",
      "Test Set\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set\")\n",
    "print(\"-\" * 10)\n",
    "print(f\"x1_train: {x1_train.shape}\")\n",
    "print(f\"x2_train: {x2_train.shape}\")\n",
    "print(f\"y_train : {y_train.shape}\")\n",
    "\n",
    "print(\"-\" * 10)\n",
    "print(f\"x1_val:   {x1_val.shape}\")\n",
    "print(f\"x2_val:   {x2_val.shape}\")\n",
    "print(f\"y_val :   {y_val.shape}\")\n",
    "print(\"-\" * 10)\n",
    "print(\"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0512810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e5aacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本參數設置，有幾個分類\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# 在語料庫裡有多少詞彙\n",
    "MAX_NUM_WORDS = 10000\n",
    "\n",
    "# 一個標題最長有幾個詞彙\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "\n",
    "# 一個詞向量的維度\n",
    "NUM_EMBEDDING_DIM = 256\n",
    "\n",
    "# LSTM 輸出的向量維度\n",
    "NUM_LSTM_UNITS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35c555c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立孿生 LSTM 架構（Siamese LSTM）\n",
    "from keras import Input\n",
    "from keras.layers import Embedding, \\\n",
    "    LSTM, concatenate, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# 分別定義 2 個新聞標題 A & B 為模型輸入\n",
    "# 兩個標題都是一個長度為 20 的數字序列\n",
    "top_input = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
    "bm_input = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
    "\n",
    "\n",
    "# 詞嵌入層\n",
    "# 經過詞嵌入層的轉換，兩個新聞標題都變成\n",
    "# 一個詞向量的序列，而每個詞向量的維度\n",
    "# 為 256\n",
    "embedding_layer = Embedding(\n",
    "    MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "top_embedded = embedding_layer(top_input)\n",
    "bm_embedded = embedding_layer(bm_input)\n",
    "\n",
    "\n",
    "# LSTM 層\n",
    "# 兩個新聞標題經過此層後\n",
    "# 為一個 128 維度向量\n",
    "shared_lstm = LSTM(NUM_LSTM_UNITS)\n",
    "top_output = shared_lstm(top_embedded)\n",
    "bm_output = shared_lstm(bm_embedded)\n",
    "\n",
    "# 串接層將兩個新聞標題的結果串接單一向量\n",
    "# 方便跟全連結層相連\n",
    "merged = concatenate(\n",
    "    [top_output, bm_output], \n",
    "    axis=-1)\n",
    "\n",
    "# 全連接層搭配 Softmax Activation\n",
    "# 可以回傳 3 個成對標題\n",
    "# 屬於各類別的可能機率\n",
    "dense = Dense(units=NUM_CLASSES, activation='softmax')\n",
    "predictions = dense(merged)\n",
    "\n",
    "# 我們的模型就是將數字序列的輸入，轉換\n",
    "# 成 3 個分類的機率的所有步驟 / 層的總和\n",
    "model = Model(inputs=[top_input, bm_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "459a4fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(\n",
    "    model, \n",
    "    to_file='model.png', \n",
    "    show_shapes=True, \n",
    "    show_layer_names=False, \n",
    "    rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b46d541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 20, 256)      2560000     ['input_7[0][0]',                \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 128)          197120      ['embedding_3[0][0]',            \n",
      "                                                                  'embedding_3[1][0]']            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256)          0           ['lstm_3[0][0]',                 \n",
      "                                                                  'lstm_3[1][0]']                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 3)            771         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,757,891\n",
      "Trainable params: 2,757,891\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34cb6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義模型的損失函數\n",
    "model.compile(\n",
    "    #優化器\n",
    "    optimizer='rmsprop',\n",
    "    #損失函數\n",
    "    loss='categorical_crossentropy',\n",
    "    #評估指標\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5eb9e8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0, 4178, 2972,    9,   80,   87,  717,\n",
       "         18,  474,    4,  968,    4,  823,   14, 1436,  721])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "656c12d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,  411,  635, 1047,   90,   35,\n",
       "        529,  408,  427,   22, 3015,  107,   68, 3330,  167])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b128dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab8b4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "564/564 [==============================] - 194s 340ms/step - loss: 0.5403 - accuracy: 0.7411 - val_loss: 0.4512 - val_accuracy: 0.7878\n",
      "Epoch 2/10\n",
      "564/564 [==============================] - 185s 328ms/step - loss: 0.4272 - accuracy: 0.8012 - val_loss: 0.4192 - val_accuracy: 0.8061\n",
      "Epoch 3/10\n",
      "564/564 [==============================] - 194s 343ms/step - loss: 0.3927 - accuracy: 0.8211 - val_loss: 0.4166 - val_accuracy: 0.8103\n",
      "Epoch 4/10\n",
      "564/564 [==============================] - 190s 337ms/step - loss: 0.3701 - accuracy: 0.8336 - val_loss: 0.3913 - val_accuracy: 0.8216\n",
      "Epoch 5/10\n",
      "564/564 [==============================] - 186s 329ms/step - loss: 0.3529 - accuracy: 0.8423 - val_loss: 0.3883 - val_accuracy: 0.8247\n",
      "Epoch 6/10\n",
      "564/564 [==============================] - 183s 325ms/step - loss: 0.3372 - accuracy: 0.8509 - val_loss: 0.3917 - val_accuracy: 0.8258\n",
      "Epoch 7/10\n",
      "564/564 [==============================] - 183s 324ms/step - loss: 0.3227 - accuracy: 0.8590 - val_loss: 0.3934 - val_accuracy: 0.8296\n",
      "Epoch 8/10\n",
      "564/564 [==============================] - 182s 324ms/step - loss: 0.3097 - accuracy: 0.8647 - val_loss: 0.3984 - val_accuracy: 0.8320\n",
      "Epoch 9/10\n",
      "564/564 [==============================] - 183s 324ms/step - loss: 0.2972 - accuracy: 0.8711 - val_loss: 0.3827 - val_accuracy: 0.8339\n",
      "Epoch 10/10\n",
      "564/564 [==============================] - 185s 327ms/step - loss: 0.2864 - accuracy: 0.8764 - val_loss: 0.3871 - val_accuracy: 0.8373\n"
     ]
    }
   ],
   "source": [
    "# 決定一次要放多少成對標題給模型訓練\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# 決定模型要看整個訓練資料集幾遍\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# 實際訓練模型\n",
    "history = model.fit(\n",
    "    # 輸入是兩個長度為 20 的數字序列\n",
    "    x=[x1_train, x2_train], \n",
    "    y=y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # 每個 epoch 完後計算驗證資料集\n",
    "    # 上的 Loss 以及準確度\n",
    "    validation_data=(\n",
    "        [x1_val, x2_val], \n",
    "        y_val\n",
    "    ),\n",
    "    # 每個 epoch 隨機調整訓練資料集\n",
    "    # 裡頭的數據以讓訓練過程更穩定\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd6377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "571cca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_zh</th>\n",
       "      <th>title2_zh</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321187</th>\n",
       "      <td>167562</td>\n",
       "      <td>59521</td>\n",
       "      <td>萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大</td>\n",
       "      <td>辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？</td>\n",
       "      <td>egypt 's presidential election failed to win m...</td>\n",
       "      <td>Lyon! Lyon officials have denied that Felipe F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321190</th>\n",
       "      <td>167564</td>\n",
       "      <td>91315</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "      <td>The Top 10 Americans believe that the Lizard M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321189</th>\n",
       "      <td>167563</td>\n",
       "      <td>167564</td>\n",
       "      <td>萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗</td>\n",
       "      <td>萨达姆被捕后告诫美国的一句话，发人深思</td>\n",
       "      <td>Will the United States wage war on Iraq withou...</td>\n",
       "      <td>A message from Saddam Hussein after he was cap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tid1    tid2                        title1_zh   \n",
       "id                                                        \n",
       "321187  167562   59521  萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大  \\\n",
       "321190  167564   91315              萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "321189  167563  167564    萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗   \n",
       "\n",
       "                          title2_zh   \n",
       "id                                    \n",
       "321187  辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？  \\\n",
       "321190    10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国   \n",
       "321189          萨达姆被捕后告诫美国的一句话，发人深思   \n",
       "\n",
       "                                                title1_en   \n",
       "id                                                          \n",
       "321187  egypt 's presidential election failed to win m...  \\\n",
       "321190  A message from Saddam Hussein after he was cap...   \n",
       "321189  Will the United States wage war on Iraq withou...   \n",
       "\n",
       "                                                title2_en  \n",
       "id                                                         \n",
       "321187  Lyon! Lyon officials have denied that Felipe F...  \n",
       "321190  The Top 10 Americans believe that the Lizard M...  \n",
       "321189  A message from Saddam Hussein after he was cap...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(\n",
    "    \"test/test.csv\", index_col=0)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "08aa10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下步驟分別對新聞標題 A、B　進行\n",
    "# 文本斷詞 / Word Segmentation\n",
    "\n",
    "\n",
    "test['title1_tokenized'] = \\\n",
    "    test.loc[:, 'title1_zh'] \\\n",
    "        .apply(jieba_tokenizer)\n",
    "test['title2_tokenized'] = \\\n",
    "    test.loc[:, 'title2_zh'] \\\n",
    "        .fillna('') \\\n",
    "        .apply(jieba_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "93aa4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 將詞彙序列轉為索引數字的序列\n",
    "#title1_tokenized 可能存在數字 使用map 把內容轉成字串\n",
    "x1_test = train.title1_tokenized.map(str)\n",
    "x2_test = train.title2_tokenized.map(str)\n",
    "\n",
    "\n",
    "x1_test = tokenizer \\\n",
    "    .texts_to_sequences(\n",
    "        test.title1_tokenized)\n",
    "x2_test = tokenizer \\\n",
    "    .texts_to_sequences(\n",
    "        test.title2_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb1c2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 20\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "x1_test = pad_sequences(x1_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x2_test = pad_sequences(x2_test, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bc06bd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2504/2504 [==============================] - 20s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(\n",
    "    [x1_test, x2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a09474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#跟我們之前討論過的一樣，模型針對每一筆成對新聞標題的輸入，會回傳給我們 3 個分類的機率值。\n",
    "\n",
    "#現在，我們只要將機率值最大的類別當作答案，並將這個結果轉回對應的文本標籤即可上傳到 Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6e33fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321187</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321190</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321189</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321193</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321191</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   Category\n",
       "0  321187  unrelated\n",
       "1  321190  unrelated\n",
       "2  321189  unrelated\n",
       "3  321193  unrelated\n",
       "4  321191  unrelated"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "\n",
    "test['Category'] = [index_to_label[idx] for idx in np.argmax(predictions, axis=1)]\n",
    "\n",
    "submission = test \\\n",
    "    .loc[:, ['Category']] \\\n",
    "    .reset_index()\n",
    "\n",
    "submission.columns = ['Id', 'Category']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b52651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
